CUDA constant memory 常量内存最佳练习


__constant__ int array[1024];
 
__global__ void kernel1(int *d_dst) {
   int tId = threadIdx.x + blockIdx.x * blockDim.x;
   d_dst[tId] = array[tId];
}
 
__global__ void kernel2(int *d_dst, int *d_src) {
   int tId = threadIdx.x + blockIdx.x * blockDim.x;
   d_dst[tId] = d_src[tId];
}
 
int main(int argc, char **argv) {
   int *d_array;
   int *d_src;
   cudaMalloc((void**)&d_array, sizeof(int) * 1024);
   cudaMalloc((void**)&d_src, sizeof(int) * 1024);
 
   int *test = new int[1024];
   memset(test, 0, sizeof(int) * 1024);
 
   for (int i = 0; i < 1024; i++) {
     test[i] = 100;
   }
 
   cudaMemcpyToSymbol(array, test, sizeof(int) * 1024);
   kernel1<<< 1, 1024 >>>(d_array);
 
   cudaMemcpy(d_src, test, sizeof(int) * 1024, cudaMemcpyHostToDevice);
   kernel2<<<1, 32 >>>(d_array, d_src),
 
   free(test);
   cudaFree(d_array);
   cudaFree(d_src);
 
   return 0;
}

Which simply shows constant memory and global memory usage. On its execution the "kernel2" executes about 4 times faster (in terms of time) than "kernel1"

I understand from the Cuda C programming guide, that this this because accesses to constant memory are getting serialized. Which brings me to the idea that constant memory can be best utilized if a warp accesses a single constant value such as integer, float, double etc. but accessing an array is not beneficial at all. In other terms, I can say a warp must access a single address in order to have any beneficial optimization/speedup gains from constant memory access. Is this correct?

I also want to know, if I keep a structure instead of a simple type in my constant memory. Any access to the structure by a thread with in a warp; is also considered as single memory access or more? I mean a structure might contain multiple simple types and array for example; when accessing these simple types, are these accesses also serialized or not?

Last question would be, in case I do have an array with constant values, which needs to be accessed via different threads within a warp; for faster access it should be kept in global memory instead of constant memory. Is that correct?

Anyone can refer me some example code where an efficient constant memory usage is shown.

regards,

Answer
I can say a warp must access a single address in order to have any beneficial optimization/speedup gains from constant memory access. Is this correct?

Yes this is generally correct and is the principal intent of usage of constant memory/constant cache. The constant cache can serve up one 32-bit quantity per cycle per SM. Therefore if each thread in a warp is accessing thesame value:

int i = array[20];
then you will have the opportunity for good benefit from the constant cache/memory. If each thread in a warp is accessing a unique quantity:

int i = array[threadIdx.x]; 
then the accesses will be serialized, and the constant data usage will be disappointing, performance-wise.

I also want to know, if I keep a structure instead of a simple type in my constant memory. Any access to the structure by a thread with in a warp; is also considered as single memory access or more?

You can certainly put structures in constant memory. The same rules apply:

int i = constant_struct_ptr->array[20]; 
has the opportunity to benefit, but

int i = constant_struct_ptr->array[threadIdx.x];
does not. If you access the same simple type structure element across threads, that is ideal for constant cache usage.

Last question would be, in case I do have an array with constant values, which needs to be accessed via different threads within a warp; for faster access it should be kept in global memory instead of constant memory. Is that correct?

Yes, if you know that in general your accesses will break the constant memory one 32-bit quantity per cycle rule, then you'll probably be better off leaving the data in ordinary global memory.

There are a variety of cuda sample codes that demonstrate usage of __constant__ data. Here are a few:

graphics volumeRender
imaging bilateralFilter
imaging convolutionTexture
finance MonteCarloGPU
and there are others.

EDIT: responding to a question in the comments, if we have a structure like this in constant memory:

struct Simple { int a, int b, int c} s;
And we access it like this:

int p = s.a + s.b + s.c;
          ^     ^     ^
          |     |     |
cycle:    1     2     3
We will have good usage of the constant memory/cache. When the C code gets compiled, under the hood it will generate machine code accesses corresponding to 1,2,3 in the diagram above. Let's imagine that access 1 occurs first. Since access 1 is to thesame memory location independent of which thread in the warp, during cycle 1, all threads will receive the value ins.a and it will take advantage of the cache for best possible benefit. Likewise for accesses 2 and 3. If on the other hand we had:

struct Simple { int a[32], int b[32], int c[32]} s;
...
int idx = threadIdx.x + blockDim.x * blockIdx.x;
int p = s.a[idx] + s.b[idx] + s.c[idx];
This would not give good usage of constant memory/cache. Instead, if this were typical of our accesses tos, we'd probably have better performance locating s in ordinary global memory.
