# MG-CFD测试

# 目录 {#目录 .TOC-Heading}

[GPU+CPU异构并行优化方案测试用例 [1](#mg-cfd测试)](#mg-cfd测试)

> [1基于OP2库开发CFD模型的基本方法介绍
> [2](#基于op2库开发cfd模型的基本方法介绍)](#基于op2库开发cfd模型的基本方法介绍)
>
> [2单层网格的空气动力学模型Airfoil介绍
> [5](#单层网格的空气动力学模型airfoil介绍)](#单层网格的空气动力学模型airfoil介绍)
>
> [2.1 基于OP2的串行版本的可执行程序
> [5](#基于op2的串行版本的可执行程序)](#基于op2的串行版本的可执行程序)
>
> [2.2编译OpenMP和CUDA版本的可执行程序
> [6](#编译openmp和cuda版本的可执行程序)](#编译openmp和cuda版本的可执行程序)
>
> [2.3编译分布式内存并行版本的可执行程序
> [8](#编译分布式内存并行版本的可执行程序)](#编译分布式内存并行版本的可执行程序)
>
> [2.4使用HDF5的数据输入与输出
> [10](#使用hdf5的数据输入与输出)](#使用hdf5的数据输入与输出)
>
> [3多重网格的空气动力学模型MGCFD介绍
> [12](#多重网格的空气动力学模型mgcfd介绍)](#多重网格的空气动力学模型mgcfd介绍)
>
> [3.1控制方程 [12](#控制方程)](#控制方程)
>
> [3.2数值离散方法 [13](#数值离散方法)](#数值离散方法)
>
> [3.3多重网格算法 [13](#多重网格算法)](#多重网格算法)
>
> [4测试用例说明 [15](#测试用例说明)](#测试用例说明)
>
> [4.1测试airfoil的用例说明
> [15](#测试airfoil的用例说明)](#测试airfoil的用例说明)
>
> [4.2 测试MGCFD的用例说明
> [15](#测试mgcfd的用例说明)](#测试mgcfd的用例说明)
>
> [参考文献 [17](#参考文献)](#参考文献)

计算流体力学（CFD）模型，就是在离散网格上求解偏微分方程，通常CFD中常用的两种代表性网格，如图1，主要是：结构网格和非结构网格，结构网格有隐式的行列关系，数据结构简单，并行度高，易于编程实施。而非结构网格模式下开发CFD模型，开发者必须显式地定义网格的拓扑关系，包括网格单元、边、节点以及相互之间的连接关系，并行实施会遇到不少问题（见优化方案设计说明书的文档）。因此，本项目研究将基于面向非结构网格开发的特定域语言OP2库的两个机翼绕流空气动力学模型作为测试用例，包括：OP2库自带的类似Rodinia-CFD测试算例的单层网格的有限体积法的Airfoil模型和多重网格法的MG-CFD模型。

下面将分别介绍OP2库开发非结构网格CFD模型的基本方法，CFD模型airfoil与MGCFD模型的基本原理，然后介绍迁移至鲲鹏920处理器机器上用来测试用例的计算规模等情况。文档中涉及非结构网格的专业术语及对应的OP2库中的API名称，如单元(cell)、边(edge)等，以及翻译成中文后不容易理解的词语，如prologation和restriction，文中均保留英文名称或中英文备注。

![](./media/image1.emf){width="3.3497331583552055in"
height="1.6093853893263341in"}

图1 计算流体力学中的两种代表性计算网格

## 1基于OP2库开发CFD模型的基本方法介绍

非结构化网格广泛地应用于计算科学和工程领域的程序开发，包括CFD领域。非结构化网格使用连接信息定义网格拓扑关系。OP2库将非结构网格数据分为4类：

-   数据集（set）

-   数据集上的数据

-   数据集之间的映射关系（连接关系）

-   数据集上的操作

这样所有的非结构网格或图可使用OP2抽象库来定义。一个数据集（set）包括：节点（nodes）、边（edges）、三角形或四边形单元。与这些数据集联系的是数据变量(如：节点坐标和边上的权重)和数据集间的映射来定义一个数据集的单元如何与周围的单元连接的。

OP2库支持C/C++和FORTRAN编程的应用程序。如图2，定义了3个数据集(set)：网格内部边(edges),
单元(cells)和边界上的边。OP2 API定义如下：

![](./media/image2.emf){width="4.536905074365705in"
height="0.7999573490813648in"}

![](./media/image3.emf){width="3.573844050743657in"
height="2.445680227471566in"}

图2 示例网格（以四边形单元为例）

连接关系通过数据集之间的映射表来声明。仅考虑内部区域的边时，edge_to_cell整数型数组给出单元与内部边的连接关系信息：

![](./media/image4.emf){width="5.1600732720909885in"
height="0.8117760279965004in"}

属于数据集edges的每个单元映射到在数据集cells中的2个单元上。op_map声明定义该映射，其中pecell维度是2，因此它的标记0和标记1映射到单元0和单元1；标记2和标记3映射到单元1和单元2，等等......当声明一个映射时，首先传递源数据集(如edges)，然后是目标数据集（如cells）。然后，传递每个数据集的维度（如2维，pecell映射每条边到2个单元）。一旦数据集和连接关系定义好了，可将数据与这些数据集联系起来。下面是单元和边上分别存储的数据（双精度）。注意到每个单元数据集上声明了一个双精度的数据，每个单元也可定义矢量的一串数据（如每个单元上存储3个数据：XYZ坐标值）：

![](./media/image5.emf){width="5.395692257217847in"
height="1.8625995188101487in"}

非结构网格模型中计算量集中的计算都可描述为数据集的操作。应用程序中，这对应于执行数据集的循环计算、通过映射关系访问数据、实施一些计算，然后（可能通过映射关系）写回到数据的数组去。如果通过映射，循环计算涉及间接访问，OP2将其标记为一次间接循环；如果不是，就是直接循环。OP2
API提供一个并行循环计算声明语法，这就允许用户在这些循环计算中声明对数据集的并行计算方式。

考虑下列的串行方式的循环计算，对图1网格中的每个内部边进行操作。每个单元使用连接到该单元的边及对应的相邻单元上的数值更新单元存储数值：

![](./media/image6.emf){width="5.234078083989501in"
height="1.6526629483814523in"}

结合基本的核函数，模型开发者可使用OP2 API声明该循环计算如下：

![](./media/image7.emf){width="5.1953226159230095in"
height="1.6616174540682416in"}

示例中的基本核函数有3个形参，并行循环声明需要访问每个声明变量（OP_INC,
OP_READ等）的访问方式。OP_ID表示存储于dedges的数据不需要任何间接访问。而另一方面，dcells通过pecell映射关系使用定义的标记(0和1)被访问。还要声明存储数据数组的维度（示例中所有的数据都是1维）。

OP2编译器处理指定并行硬件架构的代码生成与并行化。编写的应用程序代码使用OP2
API通过OP2编译器进行语法分析，并生成修改的主程序和指定后端硬件架构并行计算的代码。然后，使用传统的编译器（如GNU编译器，nvcc，Intel编译器，毕昇编译器等）编译代码，并与OP2后端并行库文件(OpenMP，MPI，CUDA，SYCL)连接生成最终的可执行程序。最后，OP2库实用MATLAB或Python脚本程序将按照OP2
API编写的串行的CFD模型代码，source-to-source转换为各种并行模式的CFD应用的可执行程序。

## 2单层网格的空气动力学模型Airfoil介绍

介绍airfoil应用及测试用例的目的是：让用户了解OP2库基础上开发应用程序的原理及编译过程。airfoil用例，基于三角形非结构网格，求解2D无粘性非线性Euler方程的应用程序，有C和Fortran两个版本。由5个并行循环组成：save_soln,
adt_calc, res_calc, bres_calc,
update，其中：save_soln和update为直接循环，其他3个为间接循环。

### 2.1 基于OP2的串行版本的可执行程序 {#基于op2的串行版本的可执行程序 .标题3}

CPU单线程的Airfoil程序只需要#include
op_seq.h头文件就可以编译和运行。主程序airfoil.cpp，执行时间推进循环，执行1000次，时间层循环调用上述的5个循环计算。各次循环对定义的op_set执行，各循环（核函数）在头文件中实施的各次迭代定义在save_soln.h,
adt_calc.h, res_calc.h, bres_calc.h,
update.h。以针对res_calc实施的循环并行化为例：

op_par_loop(res_calc, \"res_calc\", edges, ......)

其中：

（1）第1个形参是函数名称，在res_calc.h中实施；

（2）第2个形参是循环名称；

（3）第3个形参是指定op_set是在哪个位置上循环；

（4）剩下的形参适定在循环中用到的数据访问描述符。

关于op_arg_dat
API声明参考用户手册。airfoil.cpp包含OP2头文件和核函数头文件。主函数以op_init()开始，然后读入网格文件。OP2允许开发者执行自己的I/O或利用OP2的HDF5
API实施HDF5 I/O。

假设应用程序使用标准I/O读取ASCII格式文件，读取网格，分配存储数据的内存空间。然后数据传递给合适的OP2声明变量，op_set,
op_map,
op_dat。最终，实施时间层推进，时间层迭代按数据依赖关系的顺序实施op_par_loop()的循环并行化子程序，参考下面的伪代码：

![](./media/image8.emf){width="2.9585903324584426in"
height="4.631449037620297in"}

编译单线程的CPU代码，需要与OP2串行库libop2_seq.a连接，编译源码的makefile代码如下：

![](./media/image9.emf){width="4.290950349956256in"
height="1.7946325459317585in"}

还可使用OP2的代码生成器(Python脚本)生成在不同并行架构上执行的代码，然后使用目标后端设备的编译器编译源码。

### 2.2编译OpenMP和CUDA版本的可执行程序 {#编译openmp和cuda版本的可执行程序 .标题3}

使用脚本转换程序执行命令：./op2.py
airfoil.cpp。转换为airfoil_op.cpp和一个核函数文件，对应主程序中的各op_par_loop
(\*\_kernel.cpp for OpenMP and \*\_kernel.cu for CUDA)。

OpenMP程序可使用传统的C++编译器，连接到openmp后端库libop2_openmp.a。编译转换后的源码的makefile代码如下：

![](./media/image10.emf){width="4.796776027996501in"
height="3.1358737970253716in"}

转换生成的单GPU的可执行程序，使用NVIDIA
nvcc和传统的C++编译器连接到CUDA后端库libop2_cuda.a，编译源码的makefile代码如下：

![](./media/image11.emf){width="4.77718394575678in"
height="4.529221347331584in"}

使用环境变量CUDA_VISIBLE_DEVICES，选择使用计算节点上可用的GPU设备。OpenMP和CUDA版本的airfoil可执行程序的源码依赖关系及总的操作流程如图2。

![](./media/image12.emf){width="3.583626421697288in"
height="2.905450568678915in"}

图2 OpenMP和CUDA版本的airfoil应用程序编译流程

### 2.3编译分布式内存并行版本的可执行程序 {#编译分布式内存并行版本的可执行程序 .标题3}

需要用户自己编写airfoil_mpi.cpp，使用并行化I/O和网格分区库（可选择使用SCOTCH或ParMETIS库，见OP2用户手册），MPI并行化的代码转换生成，执行./op2.py
airfoil_mpi.cpp。airfoil.cpp与airfoil_mpi.cpp的区别是，后者需要使用op_decl\_\*声明，区域分解op_set,
op_map,
op_dat。MPI应用使用mpicc编译，链接到MPI后端库libop2_mpi.a。MPI_OpenMP使用传统的C++编译器编译，链接到后端库libop2_mpi.a。MPI_CUDA使用Nvidia公司的nvcc和传统的C++编译器，链接到后端库libop2_mpi_cuda.a。

MPI+OpenMP混合并行模式的airfoil可执行程序的源码编译及库依赖连接关系如图3所示，MPI+CUDA混合并行模式的airfoil可执行程序的源码编译及库依赖连接关系如图4所示。MPI+OpenMP混合并行实现鲲鹏计算节点上多核处理器的多线程的细粒度并行，充分挖掘鲲鹏920处理器的算力；而MPI+CUDA混合并行可实现鲲鹏集群上的Nvidia
Tesla
GPU集群的异构并行。注意：目前OP2不支持CPU与GPU混合执行，即所有的核函数要么全在CPU上执行，要么全在GPU上执行。

![](./media/image13.emf){width="4.986111111111111in"
height="2.6819674103237094in"}

图3 MPI+OpenMP混合并行模式的airfoil可执行程序编译

![](./media/image14.emf){width="4.791666666666667in"
height="3.632316272965879in"}

图4 MPI+CUDA混合并行模式的airfoil可执行程序编译

MPI以及MPI+OpenMP和MPI+CUDA混合并行模式的可执行程序，都使用mpirun命令运行，GPU集群并行环境下，一个MPI进程对应一个GPU。具体的源码及第三方库的链接关系如图5。

![](./media/image15.emf){width="3.555939413823272in"
height="2.451388888888889in"}

图5 MPI及混合并行模式的源码及第三方库的依赖关系图

### 2.4使用HDF5的数据输入与输出 {#使用hdf5的数据输入与输出 .标题3}

OP2使用HDF5库加速HPC环境下的大数据输入与输出（默认为同步模式），尤其是MPI并行化版本的HDF5，内部基于MPI-IO功能实现网格分区数据的合并为一个整体数据用于后期的可视化后处理。基于OP2库的串行应用程序使用串行版的HDF5库，并行化的应用程序使用并行版本的HDF5库。使用HDF5库的OP2应用程序的库文件链接关系及编译如图6。

![](./media/image16.emf){width="5.395833333333333in"
height="1.9652777777777777in"}

图6 使用HDF5库的OP2应用程序的代码生成及编译

编译单节点的串行或并行化的可执行程序，需要链接到库libop2_hdf5.a，如图7。

![](./media/image17.emf){width="4.534722222222222in"
height="3.3127919947506563in"}

图7 单GPU异构并行应用与HDF5库的链接关系图

使用MPI并行化的HDF5，不需要链接到libop2_hdf5.a,
如图8的链接关系编译生成可执行程序。

![](./media/image18.emf){width="4.638888888888889in"
height="3.7569444444444446in"}

图8 MPI+CUDA的混合并行与HDF5的编译链接

## 3多重网格的空气动力学模型MGCFD介绍

多重网格的MGCFD模型，也是基于OP2库开发的具有一定实用性的空气动力学模型，可模拟恒定态的机翼绕流，通过使用多重网格法加速流体模拟快速收敛至恒定态。由于MGCFD应用程序中即具有充分的屏幕显示处理器性能与数据通信等指标的功能，又使用了PAPI库实施监控处理的触发时间功能。因此，是测试不同架构处理器（包括CPU、GPU、FPGA等）的性能和CFD算法在不同硬件平台和软件环境下的适应性的理想工具。

MGCFD来源于HYDRA模型，HYDRA模型是Rolls-Royce公司开发的，用于涡轮发动机设计分析的气体动力学CFD模型，这类求解器主要是求解可压缩、粘性和非粘性紊流，即求解RANS的可压缩Navier-Stokes方程，包括：质量守恒、动量和能量守恒方程。紊流封闭模型采用Spalart-Allmaras方程模型，采用MUSCL的有限差分格式离散，然后块Jacobi预处理。时间项采用显格式5阶Runge-Kutta离散，改善高粘性区的数值稳定性，使用多重网格加快收敛。

### 3.1控制方程 {#控制方程 .标题3}

主要是线性化非恒定求解器算法，简要介绍如下：很多非恒定问题都是以某种已知非恒定频率产生的周期性过程，如转子-定子相互作用。模拟这些非线性问题通常需要很多周期的非恒定求解，达到收敛的周期性行为。一种方法是假设非恒定性是恒定态流场附近的小扰动：

![](./media/image19.wmf) （1）

其中，*x*和*U*分别是坐标和流体变量，上标表示恒定属性。

将式（1）代入Navier-Stokes方程，忽略扰动，生成一套线性方程组，可得如下形式的解：

![](./media/image20.wmf) （2）

其中，![](./media/image21.wmf)为非恒定的频率；![](./media/image22.wmf)为相位角度，上标表示复数的幅度。

导出的方程组的复数振幅仅与![](./media/image21.wmf)，![](./media/image22.wmf)，预设的网格移动和恒定流动特性有关。可使用局部时间步、预处理和多重网格加速求解准恒定态方程组。

### 3.2数值离散方法 {#数值离散方法 .标题3}

MGCFD基于非结构网格开发，基于边的数据结构，使用MUSCL通量差分算法，求解积分方程。离散方程使用块雅克比预处理，使用5阶龙格库塔格式迭代至恒定态。通过使用多重网格算法加速收敛至恒定态。使用显格式或隐格式双时间步方法实施非线性的非恒定计算。

### 3.3多重网格算法 {#多重网格算法 .标题3}

MGCFD使用非结构网格表征计算空间，如图9，非结构网格的灵活性体现在，通过增加网格节点（单元）数，可更精确地表征复杂的几何区域。对于多重网格，边(edge)还包括相邻网格分层的相关节点构成的边。MGCFD使用多重网格，加速迭代求解器的收敛，计算量与未知量个数线性相关。多重网格采用分级网格分层，每层网格都有自己显示的网格几何拓扑关系，粗网格从细网格获取。

从最细网格分层开始，多重网格应用使用迭代的光滑子程序降低高频误差，低频误差传递到下一级粗网格（restriction过程），作为粗网格上的高频误差，因此可以更快地被相同的子程序光滑掉。由粗一级网格的光滑误差的修正，然后再传递返回细一级网格（prolongation过程）。prolongation与restriction的顺序执行称为一个循环，即V-cycle。

多层网格间状态变量值转移采用以下算子（式1和式2），分别是restriction
过程(细网格到粗网格)和prolongation过程(粗网格到细网格)，其中![](./media/image23.wmf)表示在网格层*l*上的节点*j*上的值*u*，![](./media/image24.wmf)表示从*l*-1层网格链接到*l*层网格的节点*j*上的节点编号。

$u_{j}^{l} = \frac{\sum_{i \in N_{j}^{u}}^{}\mspace{2mu} u_{i}^{l - 1}}{\left| N_{j}^{l} \right|}$
（3）

$u_{i \in N_{j}^{l}}^{l - 1} = u_{j}^{l}$ （4）

restriction算子（式3）主要实施平均来自更细网格分层的节点值，不同网格层间的映射定义为部分输入。prolongation算子（式4）通过将粗网格值映射到细网格，执行restriction过程的反过程。MGCFD允许任意数目的相邻单元，而不是原有的固定4个单元的通量求和。根据节点间界面的表面积加权求和，因此无需做数学修正。

多重网格对计算效用的影响包括：（1）显式表征多重网格所有分层的几何网格增加了内存需求；（2）多重网格不同分层网格之间的prolongation与restriction过程修正，增加了不规则的内存访问量；（3）粗化网格降低了数据的空间局部性。

![](./media/image25.emf){width="4.986902887139108in"
height="2.871299212598425in"}

图9 两层网格间的有限体积分解的映射示意图

## 4测试用例说明

### 4.1测试airfoil的用例说明 {#测试airfoil的用例说明 .标题3}

airfoil模型是OP2库自带的测试模型，计算网格可以用程序包内的MATLAB程序（见apps\\mesh_generators目录下的脚本程序），生成不同计算规模的非结构网格输入文件new_grid.dat。生成的文件为ASCII格式，然后使用convert_mesh工具（代码在apps\\c\\airfoil\\airfoil_hdf5\\dp等路径下），将其转换为airfoil读取的HDF5格式。

本测试用例中，生成的非结构网格文件的节点、单元、内部边与边界上边的数目分别为721801，720000，1438600，2800。主要用来比较X86与Kunpeng920平台上的计算性能的不同表现。

### 4.2 测试MGCFD的用例说明 {#测试mgcfd的用例说明 .标题3}

本测试用例是项目研究的主要测试用例，用来比较X86和Kunpeng920处理器上的性能差异，以及对GPU异构代码和CPU并行代码，优化前后的性能差异。代码优化方法见《优化方案设计》说明文档。

（1）ONERA
M6机翼是一个常用于检验CFD模型精度的物理模型，见图10，测试网格文件可使用OP2自带的Matlab程序生成不同计算规模的new_grid.dat共测试程序使用。

![](./media/image26.emf){width="3.860744750656168in"
height="2.084417104111986in"}

图10 ONERA M6机翼物理模型

（2）NASA
Rotor37也是常用于CFD模拟结果精度的涡轮机物理模型，实体模型见图11。实体模型首先CAD建模并使用三角形非结构网格离散（已由OP2开发组完成并在网站上公布，见图12）。完成CFD模拟后可使用ParaView或Tecplot软件可视化压力或流场分布等，如图13，也可提取某些测点的计算数值与实测结果对比，检验其精度。本研究主要研究MGCFD的计算性能，并检验其数据一致性。

本测试用例的计算规模有3个计算规模，分别是：

-   1M: 100万个三角形单元（4层多重网格）(323Mb)；

-   8M: 800万个三角形单元（4层多重网格）(2.3Gb)；

-   25M: 2500万个三角形单元（4层多重网格）（需要发邮件索取）。

![](./media/image27.emf){width="3.349576771653543in"
height="2.870129046369204in"}

图11 NASA Rotor 37的物理模型照片

![D:\\GPGPU-dev\\warwick-HPC\\NASA
Rotor_37\\Figure-1-Geometry-of-NASA-Rotor-37-with.png](./media/image28.png){width="3.2534722222222223in"
height="2.16875in"}

图12 NASA Rotor37的CAD建模

![D:\\GPGPU-dev\\warwick-HPC\\NASA
Rotor_37\\application1_2.png](./media/image29.png){width="3.3328543307086615in"
height="2.1811789151356082in"}

图13 NASA Rotor37的CFD模拟结果可视化（压力分布）

## 参考文献

Istvan Z. Reguly, et al. Acceleration of a Full-Scale Industrial CFD
Application with OP2. IEEE Transactions On Parallel and Distributed
Systems, 2016, 27(5): 1265-1278.

Messer OEB, D\'Azevedo E, Hill J, JoubertW, Laosooksathit S, Tharrington
A. Developing mini-apps on modern platforms using multiple programming
models. In: Proceedings of the 2015 IEEE International Conference on
Cluster Computing (CLUSTER); 2015; Chicago, IL.
